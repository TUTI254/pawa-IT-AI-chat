# ğŸ§  LLM Q&A Backend (FastAPI)

This is a backend application that takes a user query and returns a response generated by a Large Language Model (LLM), specifically OpenAI's .

---

## ğŸš€ Features

- âœ… Built with **FastAPI**
- ğŸ§  Integrates with **OpenAI **
- ğŸŒ Exposes a simple `/api/ask` POST endpoint
- ğŸ” Uses `.env` for API key security
- ğŸ“¦ Easy to run locally

---

## ğŸ§‘â€ğŸ’» Requirements

- Python 3.9+
- OpenAI API Key (free-tier okay)

---

## ğŸ›  Setup Instructions

### 1. Create and activate a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

### 2. Install dependencies
pip install -r requirements.txt
```

### 3.  Set up your OpenAI API key

Create a `.env` file in the root directory of the project and add your OpenAI API key:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### 4. Run the application

```bash
uvicorn app.main:app --reload
```
Server runs at: http://127.0.0.1:8000
---


### ğŸ§¼ Notes
* This is a dev-only version of the app, rate limits are not implemented.
