# 🧠 LLM Q&A Backend (FastAPI)

This is a backend application that takes a user query and returns a response generated by a Large Language Model (LLM), specifically OpenAI's .

---

## 🚀 Features

- ✅ Built with **FastAPI**
- 🧠 Integrates with **OpenAI **
- 🌐 Exposes a simple `/api/ask` POST endpoint
- 🔐 Uses `.env` for API key security
- 📦 Easy to run locally

---

## 🧑‍💻 Requirements

- Python 3.9+
- OpenAI API Key (free-tier okay)

---

## 🛠 Setup Instructions

### 1. Create and activate a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

### 2. Install dependencies
pip install -r requirements.txt
```

### 3.  Set up your OpenAI API key

Create a `.env` file in the root directory of the project and add your OpenAI API key:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### 4. Run the application

```bash
uvicorn app.main:app --reload
```
Server runs at: http://127.0.0.1:8000
---


### 🧼 Notes
* This is a dev-only version of the app, rate limits are not implemented.
